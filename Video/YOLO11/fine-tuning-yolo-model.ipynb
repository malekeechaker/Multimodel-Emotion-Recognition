{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9923431,"sourceType":"datasetVersion","datasetId":6099066}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:37:06.631542Z","iopub.execute_input":"2024-11-16T16:37:06.632547Z","iopub.status.idle":"2024-11-16T16:37:06.637628Z","shell.execute_reply.started":"2024-11-16T16:37:06.632498Z","shell.execute_reply":"2024-11-16T16:37:06.636500Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:03:00.588973Z","iopub.execute_input":"2024-11-16T16:03:00.589412Z","iopub.status.idle":"2024-11-16T16:03:17.385674Z","shell.execute_reply.started":"2024-11-16T16:03:00.589374Z","shell.execute_reply":"2024-11-16T16:03:17.384570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom PIL import Image\nimport cv2\nfrom ultralytics import YOLO\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:03:23.146163Z","iopub.execute_input":"2024-11-16T16:03:23.146613Z","iopub.status.idle":"2024-11-16T16:03:28.217059Z","shell.execute_reply.started":"2024-11-16T16:03:23.146568Z","shell.execute_reply":"2024-11-16T16:03:28.215839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yaml_path = \"/kaggle/input/balanced-yolo-data/data.yaml\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:03:31.213317Z","iopub.execute_input":"2024-11-16T16:03:31.213904Z","iopub.status.idle":"2024-11-16T16:03:31.218517Z","shell.execute_reply.started":"2024-11-16T16:03:31.213863Z","shell.execute_reply":"2024-11-16T16:03:31.217570Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Class","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\nclass YOLOTrainer:\n    def __init__(self, task='', mode='', model='', imgsz=512, data='', plots=True, momentum=None, patience=7,\n                 device=None, epochs=None, batch=None, learning_rate=None, optimizer=None, weight_decay=None, name='', exist_ok=True):\n        self.task = task\n        self.mode = mode\n        self.model = model\n        self.imgsz = imgsz\n        self.data = data\n        self.device = device\n        self.epochs = epochs\n        self.batch = batch\n        self.name = name\n        self.exist_ok = exist_ok\n        self.learning_rate = learning_rate\n        self.optimizer = optimizer\n        self.weight_decay = weight_decay\n        self.plots = plots\n        self.momentum = momentum\n        self.patience = patience\n\n    def load_model(self):\n        model = YOLO(self.model)  # Load the YOLO model\n        return model\n\n    def train(self):\n        # Train the model\n        model = self.load_model()\n        model.train(task=self.task, \n                    mode=self.mode, \n                    data=self.data, \n                    device=self.device,\n                    epochs=self.epochs, \n                    batch=self.batch, \n                    imgsz=self.imgsz,\n                    name=self.name, \n                    exist_ok=self.exist_ok,  \n                    lr0=self.learning_rate,\n                    optimizer=self.optimizer, \n                    weight_decay=self.weight_decay,\n                    plots=self.plots,\n                    momentum=self.momentum,\n                    patience=self.patience)\n        result = model.val()\n        return result.results_dict.get('metrics/mAP50(B)', 0) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:23:29.340032Z","iopub.execute_input":"2024-11-16T16:23:29.341206Z","iopub.status.idle":"2024-11-16T16:23:29.358047Z","shell.execute_reply.started":"2024-11-16T16:23:29.341159Z","shell.execute_reply":"2024-11-16T16:23:29.356363Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Finetune using Optuna","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom optuna.pruners import MedianPruner\nfrom optuna.samplers import TPESampler\n\n# Define the Optuna optimization objective\ndef objective(trial):\n    # Suggest values for the hyperparameters\n    batch_size = trial.suggest_int('batch_size', 16, 32)  # Integer value for batch size\n    lr0 = trial.suggest_loguniform('lr0', 1e-4, 1e-1)\n    momentum = trial.suggest_uniform('momentum', 0.8, 0.98)\n    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)  # Log-uniform for weight decay\n\n    # Initialize the YOLOTrainer with the suggested hyperparameters\n    trainer = YOLOTrainer(\n        task='detect',\n        mode='train',\n        model='yolo11m.pt',  # Pretrained weights\n        data=yaml_path,  # Set your dataset config path\n        epochs=2,  # Use fewer epochs for faster trials\n        batch=batch_size,\n        learning_rate=lr0,\n        momentum=momentum,\n        optimizer='Adam',  # Can change based on preference\n        weight_decay=weight_decay,\n        name=f'optuna_trial_{trial.number}',  # Unique name for each trial\n        device='cuda'  # Assuming you're using a GPU, change as needed\n    )\n\n    # Train and evaluate\n    val_score = trainer.train()  # Replace with your validation metric\n    trial.report(val_score, step=1)  # Report intermediate results to Optuna\n\n    # Prune unpromising trials\n    if trial.should_prune():\n        raise optuna.exceptions.TrialPruned()\n\n    return val_score  # Return the evaluation metric to Optuna for optimization\n\n\n# Create an Optuna study and start optimization\nstudy = optuna.create_study(\n    direction='maximize',  # 'maximize' for higher scores (mAP, etc.)\n    sampler=TPESampler(seed=42),  # Use TPE for efficiency\n    pruner=MedianPruner(n_startup_trials=5)  # Prune after 5 trials\n)\n\nstudy.optimize(objective, n_trials=40, n_jobs=4)  # Parallelize with 4 threads (adjust as needed)\n\n# Print the best trial found by Optuna\nprint(f\"Best trial parameters: {study.best_trial.params}\")\nprint(f\"Best trial value: {study.best_trial.value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:23:33.675157Z","iopub.execute_input":"2024-11-16T16:23:33.675997Z","iopub.status.idle":"2024-11-16T16:33:09.617282Z","shell.execute_reply.started":"2024-11-16T16:23:33.675956Z","shell.execute_reply":"2024-11-16T16:33:09.615688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save Best Parameters","metadata":{}},{"cell_type":"code","source":"import json\n\nwith open(\"best_params.json\", \"w\") as f:\n    json.dump(study.best_trial.params, f)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}