{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":204352617,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-01T22:21:32.079112Z","iopub.execute_input":"2024-11-01T22:21:32.079939Z","iopub.status.idle":"2024-11-01T22:21:33.021926Z","shell.execute_reply.started":"2024-11-01T22:21:32.079887Z","shell.execute_reply":"2024-11-01T22:21:33.020907Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/balance-fer2013-data-image/__results__.html\n/kaggle/input/balance-fer2013-data-image/balanced_emotions_dataset.csv\n/kaggle/input/balance-fer2013-data-image/__notebook__.ipynb\n/kaggle/input/balance-fer2013-data-image/__output__.json\n/kaggle/input/balance-fer2013-data-image/custom.css\n/kaggle/input/balance-fer2013-data-image/__results___files/__results___8_0.png\n/kaggle/input/balance-fer2013-data-image/__results___files/__results___11_0.png\n/kaggle/input/balance-fer2013-data-image/__results___files/__results___22_0.png\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2  # For image processing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-11-01T22:21:33.023521Z","iopub.execute_input":"2024-11-01T22:21:33.023921Z","iopub.status.idle":"2024-11-01T22:21:44.984970Z","shell.execute_reply.started":"2024-11-01T22:21:33.023888Z","shell.execute_reply":"2024-11-01T22:21:44.984167Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/balance-fer2013-data-image/balanced_emotions_dataset.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-01T22:21:44.986062Z","iopub.execute_input":"2024-11-01T22:21:44.986622Z","iopub.status.idle":"2024-11-01T22:21:49.113518Z","shell.execute_reply.started":"2024-11-01T22:21:44.986584Z","shell.execute_reply":"2024-11-01T22:21:49.112568Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   emotion                                             pixels     Usage  \\\n0        0  143 144 145 145 146 145 151 149 142 135 128 13...  Training   \n1        0  182 167 154 146 134 84 30 10 3 17 27 10 7 11 6...  Training   \n2        0  207 208 208 209 208 214 176 139 116 66 124 135...  Training   \n3        0  193 193 196 203 216 229 233 243 189 114 87 95 ...  Training   \n4        0  168 195 207 208 209 207 208 204 207 207 208 20...  Training   \n\n  emotion_text  \n0        anger  \n1        anger  \n2        anger  \n3        anger  \n4        anger  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>pixels</th>\n      <th>Usage</th>\n      <th>emotion_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>143 144 145 145 146 145 151 149 142 135 128 13...</td>\n      <td>Training</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>182 167 154 146 134 84 30 10 3 17 27 10 7 11 6...</td>\n      <td>Training</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>207 208 208 209 208 214 176 139 116 66 124 135...</td>\n      <td>Training</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>193 193 196 203 216 229 233 243 189 114 87 95 ...</td>\n      <td>Training</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>168 195 207 208 209 207 208 204 207 207 208 20...</td>\n      <td>Training</td>\n      <td>anger</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-01T22:21:49.115903Z","iopub.execute_input":"2024-11-01T22:21:49.116270Z","iopub.status.idle":"2024-11-01T22:21:49.122000Z","shell.execute_reply.started":"2024-11-01T22:21:49.116191Z","shell.execute_reply":"2024-11-01T22:21:49.121134Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(28000, 4)"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Length of pixel data: {len(data.pixels[0].split())}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-01T22:21:49.123040Z","iopub.execute_input":"2024-11-01T22:21:49.123345Z","iopub.status.idle":"2024-11-01T22:21:49.135503Z","shell.execute_reply.started":"2024-11-01T22:21:49.123314Z","shell.execute_reply":"2024-11-01T22:21:49.134477Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Length of pixel data: 2304\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_pixels(img_array):\n    # Ensure the input is already a NumPy array, so no need to split or convert again\n    img_array = img_array.reshape(48, 48)  # Reshape to 48x48\n    img_array = np.expand_dims(img_array, -1)  # Add channel dimension for grayscale\n    img_array = np.repeat(img_array, 3, axis=-1)  # Convert to 3 channels for Xception\n    img_array = cv2.resize(img_array, (299, 299)) / 255.0  # Resize to 299x299 and normalize\n    return img_array\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T22:21:49.136791Z","iopub.execute_input":"2024-11-01T22:21:49.137299Z","iopub.status.idle":"2024-11-01T22:21:49.146710Z","shell.execute_reply.started":"2024-11-01T22:21:49.137251Z","shell.execute_reply":"2024-11-01T22:21:49.145747Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Process data in chunks\ndef preprocess_chunk(chunk):\n    chunk['pixels'] = chunk['pixels'].apply(lambda x: np.array(x.split(), dtype='float32'))\n    chunk['image'] = chunk['pixels'].apply(preprocess_pixels)  # Pass the array directly to preprocess_pixels\n    return chunk","metadata":{"execution":{"iopub.status.busy":"2024-11-01T22:21:49.147993Z","iopub.execute_input":"2024-11-01T22:21:49.148360Z","iopub.status.idle":"2024-11-01T22:21:49.155612Z","shell.execute_reply.started":"2024-11-01T22:21:49.148320Z","shell.execute_reply":"2024-11-01T22:21:49.154818Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Load data in chunks\nchunk_size = 1000\nchunks = []\nfor chunk in pd.read_csv(\"/kaggle/input/balance-fer2013-data-image/balanced_emotions_dataset.csv\",chunksize=chunk_size):\n    chunks.append(chunk)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T22:21:49.156677Z","iopub.execute_input":"2024-11-01T22:21:49.157009Z","iopub.status.idle":"2024-11-01T22:21:51.663129Z","shell.execute_reply.started":"2024-11-01T22:21:49.156956Z","shell.execute_reply":"2024-11-01T22:21:51.662052Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Apply preprocessing to each chunk\nprocessed_chunks = []\nfor chunk in chunks:\n    processed_chunk = preprocess_chunk(chunk)\n    processed_chunks.append(processed_chunk)\n      \nfinal_data = pd.concat(processed_chunks, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T22:21:51.664450Z","iopub.execute_input":"2024-11-01T22:21:51.664758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data['image'][0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data['image'][0].min()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data['image'][0].max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Enregistrer les donn√©es en Parquet\n#final_data.to_csv(\"/kaggle/working/preprocessed_train_dataset.csv\", index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = data['emotion'].values\nX_train, X_val, y_train, y_val = train_test_split(final_data['image'].tolist(), labels, test_size=0.2, random_state=42, stratify=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train)\nX_val = np.array(X_val)\n\n# Ensure your labels are in the correct format, e.g., one-hot encoding for multi-class classification\n\nnum_classes = len(np.unique(y_train))  # Adjust based on your classes\ny_train = to_categorical(y_train, num_classes)\ny_val = to_categorical(y_val, num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = len(np.unique(y_train))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade --force-reinstall tensorflow-addons==0.21.0\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport tensorflow_addons as tfa\n\n# Constants\nTARGET_SIZE = 750  # Set according to your input size\nBATCH_SIZE = 32  # Adjust based on your TPU\nEPOCHS = 50  # Adjust as needed\nSTEPS_PER_EPOCH = 100  # Set according to your dataset size\nVALIDATION_STEPS = 20  # Set according to your validation size\n\n# 1. Train-Test Split\n(train_img, valid_img, \n train_labels, valid_labels) = train_test_split(train_images, labels, \n                                                train_size=0.85, \n                                                random_state=0)\n\n# 2. Build Dataset Function\ndef build_dataset(images, labels=None, bsize=BATCH_SIZE, repeat=True, shuffle=True, augment=False, cache=False):\n    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n    if augment:\n        dataset = dataset.map(augmentation_function)  # Define your augmentation_function separately\n    if cache:\n        dataset = dataset.cache()\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=len(images))\n    dataset = dataset.batch(bsize)\n    if repeat:\n        dataset = dataset.repeat()\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    return dataset\n\n# 3. Tensorflow datasets\ntrain_df = build_dataset(train_img, tf.cast(train_labels, tf.float32), bsize=BATCH_SIZE, cache=True)\nvalid_df = build_dataset(valid_img, tf.cast(valid_labels, tf.float32), bsize=BATCH_SIZE, repeat=False, shuffle=False, augment=False, cache=True)\ntest_df = build_dataset(test_images, bsize=BATCH_SIZE, repeat=False, shuffle=False, augment=False, cache=False)\n\n# 4. Model Creation Function\ndef create_model():\n    conv_base = tf.keras.applications.Xception(include_top=False, weights='imagenet',\n                                               input_shape=(TARGET_SIZE, TARGET_SIZE, 3))\n    model = conv_base.output\n    model = layers.GlobalAveragePooling2D()(model)\n    model = layers.Dropout(0.3)(model)\n    model = layers.Dense(11, activation=\"sigmoid\")(model)\n    model = models.Model(conv_base.input, model)\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n                  loss=tfa.losses.SigmoidFocalCrossEntropy(alpha=0.5, gamma=2),\n                  metrics=[tf.keras.metrics.AUC(multi_label=True)])\n    return model\n\n# 5. TPU Strategy Scope\nstrategy = tf.distribute.TPUStrategy(tf.distribute.cluster_resolver.TPUClusterResolver())\nwith strategy.scope():\n    model = create_model()\n\n# Print model summary\nmodel.summary()\n\n# 6. Callbacks\nmodel_save = ModelCheckpoint('./Xcep_750_best_weights_TPU.h5', \n                             save_best_only=True, \n                             save_weights_only=True,\n                             monitor='val_loss', \n                             mode='min', verbose=1)\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0.001, \n                           patience=5, mode='min', verbose=1,\n                           restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n                              patience=2, min_delta=0.0001, \n                              mode='min', verbose=1)\n\n# 7. Training\nhistory = model.fit(\n    train_df,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_df,\n    validation_steps=VALIDATION_STEPS,\n    callbacks=[model_save, early_stop, reduce_lr]\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A simple model to test environment setup\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\n\n# Generate random data for testing\nX_test = np.random.rand(100, 299, 299, 3)\ny_test = np.random.randint(0, 10, 100)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n\n# Define a small test model\ntest_model = Sequential([\n    Flatten(input_shape=(299, 299, 3)),\n    Dense(128, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\ntest_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Run a quick test fit to confirm environment setup\ntest_model.fit(X_test, y_test, epochs=1, batch_size=16)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train,\n                    validation_data=(X_val, y_val),\n                    epochs=5,  # Adjust number of epochs as needed\n                    batch_size=32,  # Adjust batch size based on your hardware\n                    callbacks=[early_stopping])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}